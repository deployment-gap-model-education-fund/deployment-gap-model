"""
Extract gridstatus iso queues data from private bucket archive.

gridstatus code points directly at interconnection queue spreadsheets
on ISO queues websites. These spreadsheets can change without notice
and break the gridstatus API. We have a private archive of the gridstatus data
that allows us to pin the ETL code to a specific version of the raw
data. The version numbers are automatically generated by Google Cloud Storage
Object Versioning.
"""
import logging

import pandas as pd

import dbcp

logger = logging.getLogger(__name__)

# These are the earliest version we have for ISOs
# except for spp and ISONE because the recent versions
# have columns the old versions don't.
ISO_QUEUE_VERSIONS: dict[str, str] = {
    "miso": "1709776341526904",
    "caiso": "1709776259365612",
    "pjm": "1709776387308475",
    "ercot": "1709776286037540",
    "spp": "1709776417253050",
    "nyiso": "1709776369660949",
    "isone": "1709776310995150",
}


def extract(iso_queue_versions: dict[str, str] = ISO_QUEUE_VERSIONS):
    """Extract gridstatus ISO Queue data."""
    iso_queues: dict[str, pd.DataFrame] = {}
    for iso, revision_num in iso_queue_versions.items():
        uri = (
            f"gs://dgm-archive/gridstatus/interconnection_queues/parquet/{iso}.parquet"
        )
        path = dbcp.extract.helpers.cache_gcs_archive_file_locally(
            uri=uri, revision_num=revision_num
        )

        iso_queues[iso] = pd.read_parquet(path)

    return iso_queues
